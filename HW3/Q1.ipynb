{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load dataset into dataframe\n",
    "df = pd.read_csv('Social_network_Ads.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.451852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.192593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.059259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender       Age  EstimatedSalary  Purchased\n",
       "0    15624510       1  0.023810         0.029630          0\n",
       "1    15810944       1  0.404762         0.037037          0\n",
       "2    15668575       0  0.190476         0.207407          0\n",
       "3    15603246       0  0.214286         0.311111          0\n",
       "4    15804002       1  0.023810         0.451852          0\n",
       "..        ...     ...       ...              ...        ...\n",
       "395  15691863       0  0.666667         0.192593          1\n",
       "396  15706071       1  0.785714         0.059259          1\n",
       "397  15654296       0  0.761905         0.037037          1\n",
       "398  15755018       1  0.428571         0.133333          0\n",
       "399  15594041       0  0.738095         0.155556          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#normalize estimated salary, age\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "df['EstimatedSalary'] = scaler.fit_transform(df[['EstimatedSalary']])\n",
    "df['Age'] = scaler.fit_transform(df[['Age']])\n",
    "df['Gender'] = df['Gender'].map({'Female': 0, 'Male': 1})\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#do random forest with sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split into train and test\n",
    "X = df[['Gender','Age', 'EstimatedSalary']] \n",
    "y = df['Purchased']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#compute and plot different number of trees and OOB for n_estimators = 10, 50, 100, 200\n",
    "oob_scores = []\n",
    "n_trees = [10, 50, 100, 200]\n",
    "for n in n_trees:\n",
    "    rf = RandomForestClassifier(n_estimators=n, oob_score=True, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    oob_scores.append(rf.oob_score_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_trees, oob_scores, marker='o')\n",
    "plt.title('OOB Score vs Number of Trees')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('OOB Score')\n",
    "plt.xticks(n_trees)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102591</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.046015</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194236</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.036422</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402423</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.024909</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.115169</td>\n",
       "      <td>0.027648</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.217123</td>\n",
       "      <td>0.051762</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.040089</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.288940</td>\n",
       "      <td>0.064773</td>\n",
       "      <td>0.023623</td>\n",
       "      <td>0.019434</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.805108</td>\n",
       "      <td>0.040461</td>\n",
       "      <td>0.060762</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.222774</td>\n",
       "      <td>0.053466</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.010825</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.039770</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.299701</td>\n",
       "      <td>0.078663</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.030337</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.047110</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.102591      0.011724         0.012845        0.006921   \n",
       "1        0.194236      0.024178         0.009690        0.002186   \n",
       "2        0.402423      0.014284         0.024909        0.002477   \n",
       "3        0.115169      0.027648         0.014013        0.011538   \n",
       "4        0.217123      0.051762         0.010877        0.006508   \n",
       "..            ...           ...              ...             ...   \n",
       "67       0.288940      0.064773         0.023623        0.019434   \n",
       "68       0.805108      0.040461         0.060762        0.024003   \n",
       "69       0.222774      0.053466         0.015087        0.010825   \n",
       "70       0.299701      0.078663         0.011445        0.004496   \n",
       "71       0.324100      0.030337         0.012050        0.001388   \n",
       "\n",
       "   param_criterion param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "0             gini            None                       2                 50   \n",
       "1             gini            None                       2                100   \n",
       "2             gini            None                       2                200   \n",
       "3             gini            None                       5                 50   \n",
       "4             gini            None                       5                100   \n",
       "..             ...             ...                     ...                ...   \n",
       "67         entropy              20                       5                100   \n",
       "68         entropy              20                       5                200   \n",
       "69         entropy              20                      10                 50   \n",
       "70         entropy              20                      10                100   \n",
       "71         entropy              20                      10                200   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_depth': None, 'min_...           0.910714   \n",
       "1   {'criterion': 'gini', 'max_depth': None, 'min_...           0.892857   \n",
       "2   {'criterion': 'gini', 'max_depth': None, 'min_...           0.892857   \n",
       "3   {'criterion': 'gini', 'max_depth': None, 'min_...           0.928571   \n",
       "4   {'criterion': 'gini', 'max_depth': None, 'min_...           0.910714   \n",
       "..                                                ...                ...   \n",
       "67  {'criterion': 'entropy', 'max_depth': 20, 'min...           0.910714   \n",
       "68  {'criterion': 'entropy', 'max_depth': 20, 'min...           0.928571   \n",
       "69  {'criterion': 'entropy', 'max_depth': 20, 'min...           0.928571   \n",
       "70  {'criterion': 'entropy', 'max_depth': 20, 'min...           0.928571   \n",
       "71  {'criterion': 'entropy', 'max_depth': 20, 'min...           0.928571   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.928571           0.857143           0.803571   \n",
       "1            0.928571           0.857143           0.821429   \n",
       "2            0.928571           0.839286           0.821429   \n",
       "3            0.928571           0.857143           0.821429   \n",
       "4            0.928571           0.857143           0.821429   \n",
       "..                ...                ...                ...   \n",
       "67           0.928571           0.839286           0.821429   \n",
       "68           0.928571           0.839286           0.821429   \n",
       "69           0.928571           0.892857           0.821429   \n",
       "70           0.928571           0.875000           0.821429   \n",
       "71           0.928571           0.875000           0.803571   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.910714         0.882143        0.046015               47  \n",
       "1            0.892857         0.878571        0.036422               54  \n",
       "2            0.892857         0.875000        0.039123               61  \n",
       "3            0.910714         0.889286        0.042857               21  \n",
       "4            0.910714         0.885714        0.040089               27  \n",
       "..                ...              ...             ...              ...  \n",
       "67           0.910714         0.882143        0.043154               47  \n",
       "68           0.892857         0.882143        0.044607               42  \n",
       "69           0.910714         0.896429        0.039770                8  \n",
       "70           0.928571         0.896429        0.042857                1  \n",
       "71           0.910714         0.889286        0.047110               21  \n",
       "\n",
       "[72 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best score found:  0.8964285714285716\n"
     ]
    }
   ],
   "source": [
    "#make a param grid and do grid search for all the options: n_estimators: [50, 100, 200],\n",
    "#  max_depth: [None, 5, 10, 20], min_samples_split: [2, 5, 10], criterion: ['gini', 'entropy']\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "#output a table of the grid search results\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "display(results)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score found: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The best hyperparameters were {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final OOB Score:  0.8892857142857142\n"
     ]
    }
   ],
   "source": [
    "#retrain the model with the best parameters and pring the final OOB score\n",
    "best_rf = RandomForestClassifier(criterion=\"gini\", max_depth=None, random_state=42, min_samples_split=10, n_estimators=100, oob_score=True)\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"Final OOB Score: \", best_rf.oob_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. These plots are above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88        73\n",
      "           1       0.97      0.62      0.75        47\n",
      "\n",
      "    accuracy                           0.84       120\n",
      "   macro avg       0.88      0.80      0.82       120\n",
      "weighted avg       0.87      0.84      0.83       120\n",
      "\n",
      "SVM Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        73\n",
      "           1       0.92      0.94      0.93        47\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.94      0.94      0.94       120\n",
      "weighted avg       0.94      0.94      0.94       120\n",
      "\n",
      "KNN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        73\n",
      "           1       0.89      0.89      0.89        47\n",
      "\n",
      "    accuracy                           0.92       120\n",
      "   macro avg       0.91      0.91      0.91       120\n",
      "weighted avg       0.92      0.92      0.92       120\n",
      "\n",
      "Decision Tree Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        73\n",
      "           1       0.81      0.81      0.81        47\n",
      "\n",
      "    accuracy                           0.85       120\n",
      "   macro avg       0.84      0.84      0.84       120\n",
      "weighted avg       0.85      0.85      0.85       120\n",
      "\n",
      "Random Forest Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        73\n",
      "           1       0.90      0.96      0.93        47\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.94      0.94      0.94       120\n",
      "weighted avg       0.94      0.94      0.94       120\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.865278</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.832445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.942014</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.941773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.941957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-Score\n",
       "0  Logistic Regression  0.841667   0.865278  0.841667  0.832445\n",
       "1                  SVM  0.941667   0.942014  0.941667  0.941773\n",
       "2                  KNN  0.916667   0.916667  0.916667  0.916667\n",
       "3        Decision Tree  0.850000   0.850000  0.850000  0.850000\n",
       "4        Random Forest  0.941667   0.943452  0.941667  0.941957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#do logistic regression on the df\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#test it on X and y\n",
    "list_dicts = []\n",
    "names = ['Logistic Regression', 'SVM', 'KNN', 'Decision Tree', 'Random Forest']\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "#output the mean accuracy,precision, recall, f1 score\n",
    "print(\"Logistic Regression Classification Report: \")\n",
    "logreg_dict = classification_report(y_test, y_pred_log,output_dict=True)\n",
    "list_dicts.append(logreg_dict)\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "\n",
    "#do the same for SVM (rbf)\n",
    "from sklearn.svm import SVC \n",
    "#test it on X and y\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "#output the mean accuracy,precision, recall, f1 score\n",
    "print(\"SVM Classification Report: \")\n",
    "svm_dict = classification_report(y_test, y_pred_svm,output_dict=True)\n",
    "list_dicts.append(svm_dict)\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "#do the same for k-nearest neighbor (k=5)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#test it on X and y\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "#output the mean accuracy,precision, recall, f1 score\n",
    "print(\"KNN Classification Report: \")\n",
    "knn_dict = classification_report(y_test, y_pred_knn,output_dict=True)\n",
    "list_dicts.append(knn_dict)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "#do the same for decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#test it on X and y\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "#output the mean accuracy,precision, recall, f1 score\n",
    "print(\"Decision Tree Classification Report: \")\n",
    "dt_dict = classification_report(y_test, y_pred_dt,output_dict=True)\n",
    "list_dicts.append(dt_dict)\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "#test best_rf on X and y\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "#output the mean accuracy,precision, recall, f1 score\n",
    "print(\"Random Forest Classification Report: \")\n",
    "rf_dict = classification_report(y_test, y_pred_best_rf,output_dict=True)\n",
    "list_dicts.append(rf_dict)\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "\n",
    "#use the dictionaries and create a dataframe with the mean accuracy,precision, recall, f1 score\n",
    "mean_accuracy = []\n",
    "mean_precision = []\n",
    "mean_recall = []\n",
    "mean_f1 = []\n",
    "for i in range(len(list_dicts)):\n",
    "    mean_accuracy.append(list_dicts[i]['accuracy'])\n",
    "    mean_precision.append(list_dicts[i]['weighted avg']['precision'])\n",
    "    mean_recall.append(list_dicts[i]['weighted avg']['recall'])\n",
    "    mean_f1.append(list_dicts[i]['weighted avg']['f1-score'])\n",
    "#add the mean accuracy,precision, recall, f1 score to the table\n",
    "output_table = pd.DataFrame({'Model': names, 'Accuracy': mean_accuracy, 'Precision': mean_precision, 'Recall': mean_recall, 'F1-Score': mean_f1})\n",
    "display(output_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this you would take RF and SVM and do hyperparam tuning o find the best one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
